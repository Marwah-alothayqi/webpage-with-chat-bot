<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
      <title>الصوت إالى نص</title>

<Style>
/* CSS for the page*/
body{
	font-family: arial;
	font-size: 16px;
	margin: 0;
	background:lightblue;
   display: flex;
  align-items: center;
  justify-content: center;
  min-height: 100vh;
}
.covertor{
  width: 600px;
  text-align: center;

  }

h1{
	color: black;
	font-size: 50px;
      text-align: center
}
h2{
	color: grey;
	font-size: 30px;
      text-align: center
}

 button{
  padding: 12px 20px;
  background:white;
  border: 0;
  color: black;
  font-size: 18px;
  cursor: pointer;
  border-radius: 5px;}

#connect{
  padding: 12px 20px;
  background:white;
  border: 0;
  color: black;
  font-size: 18px;
  cursor: pointer;
  border-radius: 5px;}

#TE{
   width: 100%;
  height: 200px;
  border-radius: 10px;
  resize: none;
  padding: 20px;
  font-size: 20px;
  margin-top: 16px;
  color:black;
}

 
</Style>
</head>


<body>
          <div class="covertor">
          <h1>تحويل الصوت الى نص </h1>
          <h2> اضغط الزر وابدأ بالتحدث</h2>
          <button id="click_to_record">ابدأ بالتحدث</button>
          <button id="connect" onclick="connectSerial()">اتصال</button>
          <textarea name=""id="TE"></textarea>
	     </div>

	<script>
            /* JS start here */
            click_to_record.addEventListener('click',function(){
		var speech = true;
		window.SpeechRecognition = window.SpeechRecognition
						|| window.webkitSpeechRecognition;

		const recognition = new SpeechRecognition();
		recognition.interimResults = true;
		const covertor = document.querySelector('.covertor');
		covertor.appendChild(TE);
            recognition.lang='ar';

		recognition.addEventListener('result', e => {
			const transcript = Array.from(e.results)
				.map(result => result[0])
				.map(result => result.transcript)
				.join('')

			document.getElementById("TE").innerHTML = transcript;
			console.log(transcript);
                  
		});
		  recognition.start();
		});
            async function listenToPort() {
            const textDecoder = new TextDecoderStream();
            const readableStreamClosed = port.readable.pipeTo(textDecoder.writable);
            const reader = textDecoder.readable.getReader();
            // Listen to data coming from the serial device.
            while (true) {
                const { value, done } = await reader.read();
                if (done) {
                    // Allow the serial port to be closed later.
                    reader.releaseLock();
                    break;
                }
                // value is a string.
                appendToTerminal(value);
            }}


  window.watsonAssistantChatOptions = {
    integrationID: "6c198584-1b27-422b-bab0-b769ee6bd7ca", // The ID of this integration.
    region: "au-syd", // The region your integration is hosted in.
    serviceInstanceID: "1e6c6e32-bacf-4ebc-9eba-54dda3f1f27d", // The ID of your service instance.
    onLoad: function(instance) { instance.render(); }
  };
  setTimeout(function(){
    const t=document.createElement('script');
    t.src="https://web-chat.global.assistant.watson.appdomain.cloud/versions/" + (window.watsonAssistantChatOptions.clientVersion || 'latest') + "/WatsonAssistantChatEntry.js";
    document.head.appendChild(t);
  });

</script>





</body>

</html>
